$\mathbf{c} = [5, 6]$ and $\mathbf{d} = [7, 8]$, compute $\mathbf{c} \cdot \mathbf{d}$ and $\mathbf{d} \cdot \mathbf{c}$. Confirm the commutative property holds.
knitr::opts_chunk$set(echo = TRUE)
# Define the independent variable X and dependent variable Y
X <- c(1, 2, 3, 4)
Y <- c(2.2, 2.8, 3.5, 5.1)
# Create the design matrix by augmenting X with a column of ones
X_design <- cbind(1, X)  # Add a column of ones
# Call to view
X_design
# Calculate the coefficients using the OLS formula
beta <- solve(t(X_design) %*% X_design) %*% t(X_design) %*% Y
# Print to view
beta
# Going to use beta from the previous regression model calculation in F1, and X_design and Y are defined as in F1 as well
# Calculate predicted values using the obtained coefficients
Y_pred <- X_design %*% beta # X_design has our predictors, and beta contains the coefficients estimated by your linear regression model
# Calculate the mean of Y
Y_mean <- mean(Y)
# TSS: Total Sum of Squares
TSS <- sum((Y - Y_mean)^2)
# ESS: Explained Sum of Squares
ESS <- sum((Y_pred - Y_mean)^2)
# RSS: Residual Sum of Squares
RSS <- sum((Y - Y_pred)^2)
# Print the sum of squares
print(paste("TSS:", TSS))
print(paste("ESS:", ESS))
print(paste("RSS:", RSS))
# Gotta load to roll
pacman::p_load(tidyverse)
# We can define some matrices like this
matrix1 <- matrix(seq(1,10, by = 1),
ncol = 2)
matrix2 <- matrix(seq(1,10, by = 1),
nrow = 2)
# Check dimensions using dim()
dim(matrix1)
dim(matrix2)
# By the m x n / n x p rule (or saying "5x2 premultiplied by 2x5"), we see the final matrix will be of dimensions 5x5
matrix1 %*% matrix2
# Similarly, we can say that 2x5 premultiplied by 5x2 = 2x2
matrix2 %*% matrix1
# If we have this matrix
matrix1
# We can transpose using t()
t(matrix1)
# We can use solve() to find the inverse of a matrix (but this will give an error message)
solve(matrix1)
# Let's multiply it by its own transposed
matrix_square <- t(matrix1) %*% matrix1
# And then let's try to find the inverse
solve(matrix_square) # Success!
# Multiply them in different orders to see the different results
t(matrix1) %*% matrix1
matrix1 %*% t(matrix1)
solve(t(matrix1) %*% matrix1)
matrix3 <- matrix( c(1,2,3,6) ,ncol = 2, nrow = 2)
matrix3
solve(matrix3)
det(matrix3)
# Sample linear regression in R
set.seed(123)
x <- rnorm(100)
y <- 2*x + rnorm(100)
fit <- lm(y ~ x)
summary(fit)
